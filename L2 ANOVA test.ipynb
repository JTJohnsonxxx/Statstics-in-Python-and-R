{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pyhton 3.7.1 ###\n",
    "#-----L2 ANOVA------\n",
    "#~~packages\n",
    "# overall stats\n",
    "import scipy.stats as stats\n",
    "# dataframe\n",
    "import pandas as pd\n",
    "# array/math\n",
    "import numpy as np\n",
    "#time\n",
    "import time\n",
    "tStart = time.time()\n",
    "#using scipy.statsmodels for modeling\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "# post hoc\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "#data visualization\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       ID  ethnic  gender  senson  school_3  school_2  school_1  \\\n",
      "0           3  1041002  Human        0       1       206       204       102   \n",
      "1          15  1041007  Human        0       1       101       101       101   \n",
      "2          16  1041008  Human        0       1       103       103       103   \n",
      "3          30  1041012  Human        1       1       104       104       104   \n",
      "4          64  1041020  Human        0       1       107       107       107   \n",
      "\n",
      "   eco_3  eco_2   ...    item12  item13  item14  item15  item16  item17  \\\n",
      "0      0      0   ...         4       1       4       4       1       5   \n",
      "1      1      1   ...         5       1       5       5       1       5   \n",
      "2      0      0   ...         4       1       4       4       1       5   \n",
      "3      1      1   ...         3       1       2       2       1       2   \n",
      "4      0      0   ...         5       1       5       5       1       5   \n",
      "\n",
      "   item19  item20  item21  item22  \n",
      "0       4       4       1       4  \n",
      "1       3       5       1       5  \n",
      "2       4       4       4       4  \n",
      "3       2       2       1       2  \n",
      "4       5       5       1       5  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "#~~ loading data\n",
    "df_raw = pd.read_csv(r\"C:\\Users\\johnson_yang\\Desktop\\WOW_data_forStudent.csv\")#改成自己的檔案位置\n",
    "print(df_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Data info_head---------------------\n",
      "        ID  ethnic  reading_3\n",
      "0  1041002  Human         492\n",
      "1  1041007  Human         494\n",
      "2  1041008  Human         523\n",
      "3  1041012  Human         476\n",
      "4  1041020  Human         515\n",
      "---------------------Data type---------------------\n",
      "ID            int64\n",
      "ethnic       object\n",
      "reading_3     int64\n",
      "dtype: object\n",
      "---------------------ID info---------------------\n",
      "count    1.930000e+02\n",
      "mean     1.041097e+06\n",
      "std      5.585845e+01\n",
      "min      1.041001e+06\n",
      "25%      1.041049e+06\n",
      "50%      1.041097e+06\n",
      "75%      1.041145e+06\n",
      "max      1.041193e+06\n",
      "Name: ID, dtype: float64\n",
      "---------------------convert to string---------------------\n",
      "ID           object\n",
      "ethnic       object\n",
      "reading_3     int64\n",
      "dtype: object\n",
      "---------------------ethnic info---------------------\n",
      "count        193\n",
      "unique         3\n",
      "top       Human \n",
      "freq          87\n",
      "Name: ethnic, dtype: object\n",
      "---------------------ethnic counts---------------------\n",
      "Human      87\n",
      "Undead     64\n",
      "Orc        42\n",
      "Name: ethnic, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnson_yang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df = df_raw[['ID','ethnic','reading_3']]\n",
    "print('---------------------Data info_head---------------------')\n",
    "print(df.head())\n",
    "print('---------------------Data type---------------------')\n",
    "print(df.dtypes)\n",
    "print('---------------------ID info---------------------')\n",
    "print(df['ID'].describe())\n",
    "print('---------------------convert to string---------------------')\n",
    "df['ID']=df['ID'].astype(str)\n",
    "print(df.dtypes)\n",
    "print('---------------------ethnic info---------------------')\n",
    "print(df['ethnic'].describe())\n",
    "print('---------------------ethnic counts---------------------')\n",
    "print(df['ethnic'].value_counts())\n",
    "#print('---------------------reading_3 info---------------------')\n",
    "#print(rp.summary_cont(df['reading_3']))\n",
    "#print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnson_yang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\johnson_yang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\johnson_yang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\johnson_yang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#~~ normality, homogeneity\n",
    "# python 沒有R的psych套件可以直接把類別變數做頻率計算，因此要轉換data type\n",
    "\n",
    "#freq_count\n",
    "df['ethnic']=df['ethnic'].str.replace('Human','1')\n",
    "df['ethnic']=df['ethnic'].str.replace('Orc','2')\n",
    "df['ethnic']=df['ethnic'].str.replace('Undead','3')\n",
    "#convert data type\n",
    "df['ethnic']=df['ethnic'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=193, minmax=(1, 3), mean=1.8808290155440415, variance=0.7721826424870466, skewness=0.23341889971723911, kurtosis=-1.658474100053491)\n",
      "DescribeResult(nobs=193, minmax=(423, 543), mean=499.3264248704663, variance=364.53351683937825, skewness=-0.9125744541449188, kurtosis=1.6503736513748368)\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#descriptive stats (normality)\n",
    "print(stats.describe(df['ethnic']))\n",
    "print(stats.describe(df['reading_3']))\n",
    "print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartlettResult(statistic=3.39757749980998, pvalue=0.1829049335526695)\n",
      "LeveneResult(statistic=0.579736693646694, pvalue=0.5610333441234336)\n"
     ]
    }
   ],
   "source": [
    "#homogeneity\n",
    "# python要先把data做分組才能一組一組看變異數同質性(這裡暫時assign成df2做同質性檢定)\n",
    "#group data\n",
    "df2=df[['ethnic','reading_3']]\n",
    "df2=df2.groupby(['ethnic'])\n",
    "\n",
    "df2_human = df2.get_group(1)\n",
    "df2_orc = df2.get_group(2)\n",
    "df2_undead = df2.get_group(3)\n",
    "        \n",
    "print(stats.bartlett(df2_human['reading_3'],df2_orc['reading_3'], df2_undead['reading_3']))\n",
    "print(stats.levene(df2_human['reading_3'],df2_orc['reading_3'],df2_undead['reading_3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              reading_3   R-squared:                       0.154\n",
      "Model:                            OLS   Adj. R-squared:                  0.145\n",
      "Method:                 Least Squares   F-statistic:                     17.25\n",
      "Date:                Thu, 21 Mar 2019   Prob (F-statistic):           1.30e-07\n",
      "Time:                        17:05:43   Log-Likelihood:                -826.47\n",
      "No. Observations:                 193   AIC:                             1659.\n",
      "Df Residuals:                     190   BIC:                             1669.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept        505.5287      1.893    267.055      0.000     501.795     509.263\n",
      "C(ethnic)[T.2]   -19.4811      3.318     -5.872      0.000     -26.025     -12.937\n",
      "C(ethnic)[T.3]    -5.9194      2.908     -2.036      0.043     -11.655      -0.184\n",
      "==============================================================================\n",
      "Omnibus:                       25.480   Durbin-Watson:                   2.152\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               32.378\n",
      "Skew:                          -0.857   Prob(JB):                     9.32e-08\n",
      "Kurtosis:                       4.043   Cond. No.                         3.38\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#~~ one way ANOVA\n",
    "results = ols('reading_3 ~ C(ethnic)', data=df).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              df        sum_sq      mean_sq          F        PR(>F)\n",
      "C(ethnic)    2.0  10757.617935  5378.808968  17.253505  1.302420e-07\n",
      "Residual   190.0  59232.817298   311.751670        NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "# ANOVA table\n",
    "aov_table= sm.stats.anova_lm(results, typ=1)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot\n",
    "sns.boxplot(x='ethnic',y='reading_3', data=df,hue='ethnic')\n",
    "sns.catplot(x=\"ethnic\",y=\"reading_3\",hue=\"ethnic\", capsize=.2, height=6, aspect=.75,kind=\"point\",data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD,FWER=0.05\n",
      "===============================================\n",
      "group1 group2 meandiff  lower    upper   reject\n",
      "-----------------------------------------------\n",
      "  1      2    -19.4811 -27.3184 -11.6438  True \n",
      "  1      3    -5.9194  -12.7884  0.9497  False \n",
      "  2      3    13.5618   5.2786  21.8449   True \n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#~~ post-hoc\n",
    "mc = MultiComparison(df['reading_3'], df['ethnic'])\n",
    "mc_results = mc.tukeyhsd()\n",
    "print(mc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------P-value---------------------\n",
      "[0.001      0.10655048 0.001     ]\n"
     ]
    }
   ],
   "source": [
    "# p values\n",
    "from statsmodels.stats.libqsturng import psturng\n",
    "print('---------------------P-value---------------------')\n",
    "print(psturng(np.abs(mc_results.meandiffs / mc_results.std_pairs), len(mc_results.groupsunique), mc_results.df_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sum_sq     df      mean_sq          F        PR(>F)  \\\n",
      "C(ethnic)  10757.617935    2.0  5378.808968  17.253505  1.302420e-07   \n",
      "Residual   59232.817298  190.0   311.751670        NaN           NaN   \n",
      "\n",
      "             eta_sq  omega_sq  \n",
      "C(ethnic)  0.153701  0.144151  \n",
      "Residual        NaN       NaN  \n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#~~ eta squared\n",
    "#@jit\n",
    "def anova_table(aov):\n",
    "    aov['mean_sq'] = aov[:]['sum_sq']/aov[:]['df']\n",
    "    aov['eta_sq'] = aov[:-1]['sum_sq']/sum(aov['sum_sq'])\n",
    "    aov['omega_sq'] = (aov[:-1]['sum_sq']-(aov[:-1]['df']*aov['mean_sq'][-1]))/(sum(aov['sum_sq'])+aov['mean_sq'][-1])\n",
    "    cols = ['sum_sq', 'df', 'mean_sq', 'F', 'PR(>F)', 'eta_sq', 'omega_sq']\n",
    "    aov = aov[cols]\n",
    "    return aov\n",
    "\n",
    "print(anova_table(aov_table))\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It cost 2.076333999633789 sec\n"
     ]
    }
   ],
   "source": [
    "tEnd = time.time()\n",
    "print(\"It cost\",tEnd-tStart,\"sec\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
